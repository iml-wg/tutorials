{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i2.wp.com/www.ai-claudio.com/wp-content/uploads/2017/05/keras-tensorflow-logo.jpg?resize=500%2C201\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import h5py\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "lr_init=1.e-3    Initial learning rate.<br>\n",
    "batch_size=64   Batch size for gradient update during training.<br>\n",
    "train_size=320  Training size per decay. max 160000 <br>\n",
    "valid_size=44   Validation size per decay. max 44800 <br>\n",
    "test_size=44    Test size per decay. max 44200 <br>\n",
    "epochs=25 <br>\n",
    "doGPU=False     Enable GPU memory optimizations. Requires tensorflow-gpu with cudnn <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_init=1.e-3\n",
    "batch_size=64\n",
    "train_size=320\n",
    "valid_size=44\n",
    "test_size=44\n",
    "epochs=25\n",
    "doGPU=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doGPU:\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Image Data ###\n",
    "\n",
    "img_rows, img_cols, nb_channels = 32, 32, 2\n",
    "input_dir = 'data'\n",
    "decays = ['SinglePhotonPt50_IMGCROPS_n249k_RHv1', 'SingleElectronPt50_IMGCROPS_n249k_RHv1']\n",
    "\n",
    "def load_data(decays, start, stop):\n",
    "    global input_dir\n",
    "    dsets = [h5py.File('%s/%s.hdf5'%(input_dir,decay)) for decay in decays]\n",
    "    X = np.concatenate([dset['/X'][start:stop] for dset in dsets])\n",
    "    y = np.concatenate([dset['/y'][start:stop] for dset in dsets])\n",
    "    assert len(X) == len(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Training/Validation and Tests Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set range of training set\n",
    "train_start, train_stop = 0, train_size\n",
    "assert train_stop > train_start\n",
    "assert (len(decays)*train_size) % batch_size == 0\n",
    "X_train, y_train = load_data(decays,train_start,train_stop)\n",
    "\n",
    "# Set range of validation set\n",
    "valid_start, valid_stop = 160000, 160000+valid_size\n",
    "assert valid_stop  >  valid_start\n",
    "assert valid_start >= train_stop\n",
    "X_valid, y_valid = load_data(decays,valid_start,valid_stop)\n",
    "\n",
    "# Set range of test set\n",
    "test_start, test_stop = 204800, 204800+test_size\n",
    "assert test_stop  >  test_start\n",
    "assert test_start >= valid_stop\n",
    "X_test, y_test = load_data(decays,test_start,test_stop)\n",
    "\n",
    "samples_requested = len(decays) * (train_size + valid_size + test_size)\n",
    "samples_available = len(y_train) + len(y_valid) + len(y_test)\n",
    "assert samples_requested == samples_available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot  sample of training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[1,:,:,0])\n",
    "plt.title(\"Channel 1\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1,:,:,1])\n",
    "plt.title(\"Channel 2\")\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define CNN Model ###\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal', input_shape=(img_rows, img_cols, nb_channels)))\n",
    "model.add(Conv2D(16, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n",
    "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='TruncatedNormal'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='TruncatedNormal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='TruncatedNormal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer='TruncatedNormal'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr_init), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Model ###\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1.e-6)\n",
    "history=model.fit(X_train, y_train,\\\n",
    "        batch_size=batch_size,\\\n",
    "        epochs=epochs,\\\n",
    "        validation_data=(X_valid, y_valid),\\\n",
    "        callbacks=[reduce_lr],\\\n",
    "        verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate Model ###\n",
    "\n",
    "# Evaluate on validation set\n",
    "score = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('\\nValidation loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_valid)\n",
    "fpr, tpr, _ = roc_curve(y_valid, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Validation ROC AUC:', roc_auc)\n",
    "\n",
    "# Evaluate on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\nTest loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Test ROC AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(loc=2, prop={'size': 15})\n",
    "plt.plot(fpr, tpr, label='Proteus Model 1 (ROC-AUC = {:.3f})'.format(roc_auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
